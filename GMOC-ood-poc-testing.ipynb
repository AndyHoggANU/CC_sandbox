{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Overturning Streamfunction\n",
    "\n",
    "This script is a test case for the OOD proof of concept testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import cosima_cookbook as cc\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cmocean as cm\n",
    "from dask.distributed import Client,Scheduler\n",
    "from dask_jobqueue import SLURMCluster"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# For Gadi-jupyter\n",
    "client = Client(n_workers=4)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = cc.database.create_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_psi(psi_avg, clev=np.arange(-25,25,2)):\n",
    "\n",
    "    p1 = plt.contourf(psi_avg.grid_yu_ocean, \n",
    "                 psi_avg.potrho, \n",
    "                 psi_avg, \n",
    "                 cmap=cm.cm.delta,levels=clev,extend='both')\n",
    "    plt.contour(psi_avg.grid_yu_ocean, \n",
    "                psi_avg.potrho, \n",
    "                psi_avg, levels=clev, colors='k', linewidths=0.25)\n",
    "    plt.contour(psi_avg.grid_yu_ocean,\n",
    "                psi_avg.potrho, psi_avg,\n",
    "                levels=[0.0,], colors='k', linewidths=0.5)\n",
    "    plt.gca().invert_yaxis()\n",
    "    \n",
    "    plt.ylim((1037.5,1034))\n",
    "    plt.ylabel('Potential Density (kg m$^{-3}$)')\n",
    "    plt.xlabel('Latitude ($^\\circ$N)')\n",
    "    plt.xlim([-75,85])\n",
    "    \n",
    "    return p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OOD\n",
    "cluster = SLURMCluster(cores=2,memory=\"31GB\")\n",
    "client = Client(cluster)\n",
    "cluster.scale(cores=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://10.0.96.2:36989</li>\n",
       "  <li><b>Dashboard: </b><a href='http://10.0.96.2:32971/status' target='_blank'>http://10.0.96.2:32971/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>6</li>\n",
       "  <li><b>Cores: </b>6</li>\n",
       "  <li><b>Memory: </b>86.64 GiB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://10.0.96.2:36989' processes=6 threads=6, memory=86.64 GiB>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(cores=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.core - ERROR - 'tcp://127.0.0.1:40471'\n",
      "Traceback (most recent call last):\n",
      "  File \"/g/data3/hh5/public/apps/miniconda3/envs/analysis3-21.04/lib/python3.8/site-packages/distributed/core.py\", line 573, in handle_stream\n",
      "    handler(**merge(extra, msg))\n",
      "  File \"/g/data3/hh5/public/apps/miniconda3/envs/analysis3-21.04/lib/python3.8/site-packages/distributed/scheduler.py\", line 5061, in handle_release_data\n",
      "    ws: WorkerState = parent._workers_dv[worker]\n",
      "KeyError: 'tcp://127.0.0.1:40471'\n",
      "distributed.utils - ERROR - 'tcp://127.0.0.1:40471'\n",
      "Traceback (most recent call last):\n",
      "  File \"/g/data3/hh5/public/apps/miniconda3/envs/analysis3-21.04/lib/python3.8/site-packages/distributed/utils.py\", line 671, in log_errors\n",
      "    yield\n",
      "  File \"/g/data3/hh5/public/apps/miniconda3/envs/analysis3-21.04/lib/python3.8/site-packages/distributed/scheduler.py\", line 4073, in add_worker\n",
      "    await self.handle_worker(comm=comm, worker=address)\n",
      "  File \"/g/data3/hh5/public/apps/miniconda3/envs/analysis3-21.04/lib/python3.8/site-packages/distributed/scheduler.py\", line 5161, in handle_worker\n",
      "    await self.handle_stream(comm=comm, extra={\"worker\": worker})\n",
      "  File \"/g/data3/hh5/public/apps/miniconda3/envs/analysis3-21.04/lib/python3.8/site-packages/distributed/core.py\", line 573, in handle_stream\n",
      "    handler(**merge(extra, msg))\n",
      "  File \"/g/data3/hh5/public/apps/miniconda3/envs/analysis3-21.04/lib/python3.8/site-packages/distributed/scheduler.py\", line 5061, in handle_release_data\n",
      "    ws: WorkerState = parent._workers_dv[worker]\n",
      "KeyError: 'tcp://127.0.0.1:40471'\n",
      "distributed.core - ERROR - Exception while handling op register-worker\n",
      "Traceback (most recent call last):\n",
      "  File \"/g/data3/hh5/public/apps/miniconda3/envs/analysis3-21.04/lib/python3.8/site-packages/distributed/core.py\", line 501, in handle_comm\n",
      "    result = await result\n",
      "  File \"/g/data3/hh5/public/apps/miniconda3/envs/analysis3-21.04/lib/python3.8/site-packages/distributed/scheduler.py\", line 4073, in add_worker\n",
      "    await self.handle_worker(comm=comm, worker=address)\n",
      "  File \"/g/data3/hh5/public/apps/miniconda3/envs/analysis3-21.04/lib/python3.8/site-packages/distributed/scheduler.py\", line 5161, in handle_worker\n",
      "    await self.handle_stream(comm=comm, extra={\"worker\": worker})\n",
      "  File \"/g/data3/hh5/public/apps/miniconda3/envs/analysis3-21.04/lib/python3.8/site-packages/distributed/core.py\", line 573, in handle_stream\n",
      "    handler(**merge(extra, msg))\n",
      "  File \"/g/data3/hh5/public/apps/miniconda3/envs/analysis3-21.04/lib/python3.8/site-packages/distributed/scheduler.py\", line 5061, in handle_release_data\n",
      "    ws: WorkerState = parent._workers_dv[worker]\n",
      "KeyError: 'tcp://127.0.0.1:40471'\n",
      "tornado.application - ERROR - Exception in callback functools.partial(<function TCPServer._handle_connection.<locals>.<lambda> at 0x1465b974b940>, <Task finished name='Task-783645' coro=<BaseTCPListener._handle_stream() done, defined at /g/data3/hh5/public/apps/miniconda3/envs/analysis3-21.04/lib/python3.8/site-packages/distributed/comm/tcp.py:476> exception=KeyError('tcp://127.0.0.1:40471')>)\n",
      "Traceback (most recent call last):\n",
      "  File \"/g/data3/hh5/public/apps/miniconda3/envs/analysis3-21.04/lib/python3.8/site-packages/tornado/ioloop.py\", line 741, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/g/data3/hh5/public/apps/miniconda3/envs/analysis3-21.04/lib/python3.8/site-packages/tornado/tcpserver.py\", line 331, in <lambda>\n",
      "    gen.convert_yielded(future), lambda f: f.result()\n",
      "  File \"/g/data3/hh5/public/apps/miniconda3/envs/analysis3-21.04/lib/python3.8/site-packages/distributed/comm/tcp.py\", line 493, in _handle_stream\n",
      "    await self.comm_handler(comm)\n",
      "  File \"/g/data3/hh5/public/apps/miniconda3/envs/analysis3-21.04/lib/python3.8/site-packages/distributed/core.py\", line 501, in handle_comm\n",
      "    result = await result\n",
      "  File \"/g/data3/hh5/public/apps/miniconda3/envs/analysis3-21.04/lib/python3.8/site-packages/distributed/scheduler.py\", line 4073, in add_worker\n",
      "    await self.handle_worker(comm=comm, worker=address)\n",
      "  File \"/g/data3/hh5/public/apps/miniconda3/envs/analysis3-21.04/lib/python3.8/site-packages/distributed/scheduler.py\", line 5161, in handle_worker\n",
      "    await self.handle_stream(comm=comm, extra={\"worker\": worker})\n",
      "  File \"/g/data3/hh5/public/apps/miniconda3/envs/analysis3-21.04/lib/python3.8/site-packages/distributed/core.py\", line 573, in handle_stream\n",
      "    handler(**merge(extra, msg))\n",
      "  File \"/g/data3/hh5/public/apps/miniconda3/envs/analysis3-21.04/lib/python3.8/site-packages/distributed/scheduler.py\", line 5061, in handle_release_data\n",
      "    ws: WorkerState = parent._workers_dv[worker]\n",
      "KeyError: 'tcp://127.0.0.1:40471'\n",
      "distributed.nanny - WARNING - Worker process still alive after 3 seconds, killing\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "experiment = '01deg_jra55v13_ryf9091'\n",
    "start_time='1950-01-01'\n",
    "end_time='1999-12-31'\n",
    "psi = cc.querying.getvar(experiment,'ty_trans_rho',session,start_time=start_time, end_time=end_time, frequency='1 monthly')\n",
    "psi = psi.mean('time').sum('grid_xt_ocean')*1.0e-9\n",
    "psi_avg = psi.cumsum('potrho') -  psi.sum('potrho')\n",
    "psi_avg.load()\n",
    "\n",
    "p1 = plot_psi(psi_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open On Demand \n",
    "| Workers | Cores | Memory | Number of years | CPU Time (s) | Wall Time (s) |  Notes | \n",
    "|----|----|----| ----|----|----|----|\n",
    "| 0 | ? | ? | 1 | died | | Assume I don't have enough memory without a cluster |\n",
    "| 4 | 8 | 28.88 Gb | 1 | 110 | 165 |  SLURMCluster(cores=8,memory=\"31GB\")|\n",
    "| 8 | 16 | 57.76 Gb | 1 | 97 | 129 |   |\n",
    "| 8 | 16 | 57.76 Gb | 1 | 295 | 724 | New session. Seemed slow to start. Very slow to finish?? Not sure what is wrong here. |\n",
    "| 8 | 16 | 57.76 Gb | 1 | 92 | 116 | Same session and cluster as above. Strange. Let's try again! |\n",
    "| 8 | 16 | 57.76 Gb | 1 | 96 | 116 | Third time, just to check. |\n",
    "| 8 | 32 | 57.76 Gb | 1 | 490 | 1554 | Trying SLURMCluster(cores=16,memory=\"31GB\"). Very slow again...  |\n",
    "| 16 | 16 | 115.52 GB | 1 | 96 | 120 | Hmm ... |\n",
    "| 32 | 32 | 231.04 GB | 1 | 97 | 120 | OK. | \n",
    "| 32 | 32 | 231.04 GB | 5 |  |  | Gave up, for now. | \n",
    "\n",
    "\n",
    "## Gadi-Jupyter - normal queue\n",
    "| Workers | Cores | Memory | # of years | CPU Time (s) | Wall Time (s) |  Notes | \n",
    "|----|----|----| ----|----|----|----|\n",
    "| 8 | 16 | 64 Gb | 1 | 48 | 69 |   |\n",
    "| 8 | 16 | 64 Gb | 1 | 47 | 57 | Second run just to check  |\n",
    "| 8 | 16 | 64 Gb | 5 | 377 | 513 |  Slower than it should have been. Struggled with memory. |\n",
    "| 8 | 16 | 64 Gb | 5 | 423 | 630 |  Checking. |\n",
    "| 4 | 16 | 64 Gb | 10 | 1725 | 2282 |  Struggling! ... |\n",
    "| 4 | 48 | 188.57 Gb | 10 | 586 | 767 |  Better! |\n",
    "| 8 | 48 | 188.57 Gb | 10 | 294 | 388 |  Perhaps optimal? |\n",
    "| 16 | 48 | 188.57 Gb | 10 | 417 | 487 | Looked pretty inefficient while running, but quicker. |\n",
    "| 8 | 16 | 64 Gb | 50 | - | - | Ran out of memory  |\n",
    "| 8 | 48 | 188.57 Gb | 50 | - | - |  Garbage collection warnings ... killed workers, etc.|\n",
    "| 4 | 48 | 188.57 Gb | 50 | - | - |  |\n",
    "\n",
    "We would like to be able to scale this calculation up to do 100 years at once. Gadi-jupyter can't do this, but we would like OOD to be able to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does Slurm allocate cores and memory?\n",
    "\n",
    "| SLURM cores | SLURM memory | cluster.scale(cores=?)  | client workers | client cores | client memory |\n",
    "|---|---|---|---|---|---|\n",
    "| 16 | 31 | 4 | 4 | 16 |28.88 | \n",
    "| 16 | 31 | 8 | 4 | 16 |28.88 | \n",
    "| 16 | 31 | 16 | 4 | 16 | 28.88 | \n",
    "| 16 | 31 | 32 | 8 | 32 | 57.76 | \n",
    "| 8 | 31 | 4 | 4 | 8 | 28.88 |\n",
    "| 8 | 31 | 8 | 8 | 8 | 28.88 |\n",
    "| 8 | 31 | 16 | 8 | 16 | 57.76 |\n",
    "| 8 | 31 | 32 | 16 | 32 | 115.52 |\n",
    "| 4 | 31 | 4 | 4 | 4 | 28.88 |\n",
    "| 4 | 31 | 8 | 8 | 8 | 57.76 |\n",
    "| 4 | 31 | 16 |16 | 16 | 115.52 |\n",
    "| 4 | 31 | 32 | 32 | 32 | 231.04 |\n",
    "| 2 | 31 | 4 | 4 | 4 | 57.76 |\n",
    "| 2 | 31 | 8 | 6 | 6 | 86.64 |\n",
    "\n",
    "I still find this strange -- but I think the way we should use this is:\n",
    "* if you want multiple threads per worker, go for `SLURMCluster(cores=16,memory=\"31GB\")`\n",
    "* if you want lots of memory per worker, go for `SLURMCluster(cores=4,memory=\"31GB\")`\n",
    "* Then scale up cores, or number of workers via `cluster.scale()`\n",
    "* As far as we can tell, `cluster.adapt()` doesn't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:analysis3-21.04]",
   "language": "python",
   "name": "conda-env-analysis3-21.04-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
